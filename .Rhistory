head(topTerms, 200)
# load necessary libraries
library(tm)
library(topicmodels)
library(koRpus)
library(wordcloud)
#load stop words
ir_stoplist <- read.csv("ir_stoplist.csv")
#functions
abstractLemmas <- function(file){
tagged.text <- treetag(file, treetagger = "manual",
lang="en", TT.options=list(path="/Users/msaxton/treetagger/",
preset="en"))
results <- taggedText(tagged.text)
lemmas <- results[,"lemma"]
return(lemmas)
}
#the following function needs to be re-written to accept a character vector as arg
makeCorpus <- function(filenames){
file_path <- paste("./iliff_corpus/", filenames, sep="")
files <- lapply(file_path, abstractLemmas)
text_corpus <- Corpus(VectorSource(files))
return(text_corpus)
}
preprocessCorpus <- function(text_corpus){
text_corpus <- tm_map(text_corpus, stripWhitespace)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, removeWords, ir_stoplist)
# text_corpus <- tm_map(text_corpus, stemDocument) #Stemming not necessary b/c the corpus has been lemmatized
text_corpus <- tm_map(text_corpus, removeNumbers)
text_corpus <- tm_map(text_corpus, removePunctuation)
return(text_corpus)
}
createDTM <- function(corpus, filenames){
dtm <- DocumentTermMatrix(corpus)
rownames(dtm) <- filenames
return(dtm)
}
topTerms <- function(dtm){
# freq <- findFreqTerms(dtm) #not sure what this line does
sortfreq <- sort(colSums(as.matrix(dtm)), decreasing = TRUE)
return(sortfreq)
}
compareAssocTerms <- function(dtm_1, dtm_2, dtm_3, term, threshold=0.6){
print(findAssocs(dtm_1, term, threshold))
print(findAssocs(dtm_2, term, threshold))
print(findAssocs(dtm_3, term, threshold))
}
filenames60s <- list.files("./iliff_corpus", pattern="^5|^6")
corpus60s <- makeCorpus(filenames60s)
dtm60s <- createDTM(corpus60s, filenames60s)
topTerms <-topTerms(dtm60s)
topTerms(head, 200)
head(topTerms, 200)
preprocessCorpus <- function(text_corpus){
text_corpus <- tm_map(text_corpus, stripWhitespace)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, removeWords(ir_stoplist))
# text_corpus <- tm_map(text_corpus, stemDocument) #Stemming not necessary b/c the corpus has been lemmatized
text_corpus <- tm_map(text_corpus, removeNumbers)
text_corpus <- tm_map(text_corpus, removePunctuation)
return(text_corpus)
}
corpus60s <- makeCorpus(filenames60s)
corpus60s <- preprocessCorpus(corpus60s)
library(tm)
library(topicmodels)
library(koRpus)
library(wordcloud)
ir_stopwords <- read.csv(ir_stoplist.csv)
ir_stopwords <- read.csv("ir_stoplist.csv")
abstractLemmas <- function(file){
tagged.text <- treetag(file, treetagger = "manual",
lang="en", TT.options=list(path="/Users/msaxton/treetagger/",
preset="en"))
results <- taggedText(tagged.text)
lemmas <- results[,"lemma"]
return(lemmas)
}
#the following function needs to be re-written to accept a character vector as arg
makeCorpus <- function(filenames){
file_path <- paste("./iliff_corpus/", filenames, sep="")
files <- lapply(file_path, abstractLemmas)
text_corpus <- Corpus(VectorSource(files))
return(text_corpus)
}
preprocessCorpus <- function(text_corpus){
text_corpus <- tm_map(text_corpus, stripWhitespace)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, removeWords, stopwords("english"))
# text_corpus <- tm_map(text_corpus, stemDocument) #Stemming not necessary b/c the corpus has been lemmatized
text_corpus <- tm_map(text_corpus, removeNumbers)
text_corpus <- tm_map(text_corpus, removePunctuation)
return(text_corpus)
}
createDTM <- function(corpus, filenames){
dtm <- DocumentTermMatrix(corpus)
rownames(dtm) <- filenames
return(dtm)
}
topTerms <- function(dtm){
# freq <- findFreqTerms(dtm) #not sure what this line does
sortfreq <- sort(colSums(as.matrix(dtm)), decreasing = TRUE)
return(sortfreq)
}
compareAssocTerms <- function(dtm_1, dtm_2, dtm_3, term, threshold=0.6){
print(findAssocs(dtm_1, term, threshold))
print(findAssocs(dtm_2, term, threshold))
print(findAssocs(dtm_3, term, threshold))
}
filenames60s <- list.files("./iliff_corpus", pattern="^5|^6")
corpus60s <- makeCorpus(filenames60s)
preprocessCorpus <- function(text_corpus){
text_corpus <- tm_map(text_corpus, stripWhitespace)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, removeWords, ir_stopwords)
# text_corpus <- tm_map(text_corpus, stemDocument) #Stemming not necessary b/c the corpus has been lemmatized
text_corpus <- tm_map(text_corpus, removeNumbers)
text_corpus <- tm_map(text_corpus, removePunctuation)
return(text_corpus)
}
corpus60s <- makeCorpus(filenames60s)
corpus60s <- preprocessCorpus(corpus60s)
dtm60s <- createDTM(corpus60s, filenames60s)
corpus60s <- preprocessCorpus(corpus60s)
library(tm)
library(topicmodels)
library(koRpus)
library(wordcloud)
abstractLemmas <- function(file){
tagged.text <- treetag(file, treetagger = "manual",
lang="en", TT.options=list(path="/Users/msaxton/treetagger/",
preset="en"))
results <- taggedText(tagged.text)
lemmas <- results[,"lemma"]
return(lemmas)
}
makeCorpus <- function(filenames){
file_path <- paste("./iliff_corpus/", filenames, sep="")
files <- lapply(file_path, abstractLemmas)
text_corpus <- Corpus(VectorSource(files))
return(text_corpus)
}
preprocessCorpus <- function(text_corpus){
text_corpus <- tm_map(text_corpus, stripWhitespace)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, removeWords, stopwords("english"))
# text_corpus <- tm_map(text_corpus, stemDocument) #Stemming not necessary b/c the corpus has been lemmatized
text_corpus <- tm_map(text_corpus, removeNumbers)
text_corpus <- tm_map(text_corpus, removePunctuation)
return(text_corpus)
}
createDTM <- function(corpus, filenames){
dtm <- DocumentTermMatrix(corpus)
rownames(dtm) <- filenames
return(dtm)
}
topTerms <- function(dtm){
# freq <- findFreqTerms(dtm) #not sure what this line does
sortfreq <- sort(colSums(as.matrix(dtm)), decreasing = TRUE)
return(sortfreq)
}
compareAssocTerms <- function(dtm_1, dtm_2, dtm_3, term, threshold=0.6){
print(findAssocs(dtm_1, term, threshold))
print(findAssocs(dtm_2, term, threshold))
print(findAssocs(dtm_3, term, threshold))
}
filenames60s <- list.files("./iliff_corpus", pattern="^5|^6")
corpus60s <- makeCorpus(filenames60s)
warnings()
dtm60s <- createDTM(corpus60s, filenames60s)
terms <- topTerms(dtm60s)
head(terms, 50)
ir_stopwords <- read.csv("ir_stoplist.csv")
preprocessCorpus <- function(text_corpus){
text_corpus <- tm_map(text_corpus, stripWhitespace)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, removeWords, c(stopwords("english"),
ir_stopwords))
# text_corpus <- tm_map(text_corpus, stemDocument) #Stemming not necessary b/c the corpus has been lemmatized
text_corpus <- tm_map(text_corpus, removeNumbers)
text_corpus <- tm_map(text_corpus, removePunctuation)
return(text_corpus)
}
corpus60s <- preprocessCorpus(corpus60s)
preprocessCorpus <- function(text_corpus){
text_corpus <- tm_map(text_corpus, stripWhitespace)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, removeWords, c(stopwords("english"),ir_stopwords))
text_corpus <- tm_map(text_corpus, removeNumbers)
text_corpus <- tm_map(text_corpus, removePunctuation)
return(text_corpus)
}
corpus60s <- preprocessCorpus(corpus60s)
dtm60s <- createDTM(corpus60s, filenames60s)
preprocessCorpus <- function(text_corpus){
text_corpus <- tm_map(text_corpus, stripWhitespace)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, removeWords, c(stopwords("english"))
text_corpus <- tm_map(text_corpus, removeNumbers)
text_corpus <- tm_map(text_corpus, removePunctuation)
return(text_corpus)
}
preprocessCorpus <- function(text_corpus){
text_corpus <- tm_map(text_corpus, stripWhitespace)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, removeWords, (stopwords("english"))
text_corpus <- tm_map(text_corpus, removeNumbers)
text_corpus <- tm_map(text_corpus, removePunctuation)
return(text_corpus)
}
library(tm)
library(topicmodels)
library(koRpus)
library(wordcloud)
#functions
abstractLemmas <- function(file){
tagged.text <- treetag(file, treetagger = "manual",
lang="en", TT.options=list(path="/Users/msaxton/treetagger/",
preset="en"))
results <- taggedText(tagged.text)
lemmas <- results[,"lemma"]
return(lemmas)
}
#the following function needs to be re-written to accept a character vector as arg
makeCorpus <- function(filenames){
file_path <- paste("./iliff_corpus/", filenames, sep="")
files <- lapply(file_path, abstractLemmas)
text_corpus <- Corpus(VectorSource(files))
return(text_corpus)
}
preprocessCorpus <- function(text_corpus){
text_corpus <- tm_map(text_corpus, stripWhitespace)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, removeWords, stopwords("english"))
# text_corpus <- tm_map(text_corpus, stemDocument) #Stemming not necessary b/c the corpus has been lemmatized
text_corpus <- tm_map(text_corpus, removeNumbers)
text_corpus <- tm_map(text_corpus, removePunctuation)
return(text_corpus)
}
createDTM <- function(corpus, filenames){
dtm <- DocumentTermMatrix(corpus)
rownames(dtm) <- filenames
return(dtm)
}
topTerms <- function(dtm){
# freq <- findFreqTerms(dtm) #not sure what this line does
sortfreq <- sort(colSums(as.matrix(dtm)), decreasing = TRUE)
return(sortfreq)
}
compareAssocTerms <- function(dtm_1, dtm_2, dtm_3, term, threshold=0.6){
print(findAssocs(dtm_1, term, threshold))
print(findAssocs(dtm_2, term, threshold))
print(findAssocs(dtm_3, term, threshold))
}
# load and divide corpus by decade
filenames60s <- list.files("./iliff_corpus", pattern="^5|^6")
corpus60s <- makeCorpus(filenames60s)
corpus60s <- preprocessCorpus(corpus60s)
dtm60s <- createDTM(corpus60s, filenames60s)
terms <- topTerms(dtm60s)
head(terms)
ir_stopwords <- read.csv("ir_stoplist.csv")
preprocessCorpus <- function(text_corpus){
text_corpus <- tm_map(text_corpus, stripWhitespace)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, removeWords, ir_stopwords)
# text_corpus <- tm_map(text_corpus, stemDocument) #Stemming not necessary b/c the corpus has been lemmatized
text_corpus <- tm_map(text_corpus, removeNumbers)
text_corpus <- tm_map(text_corpus, removePunctuation)
return(text_corpus)
}
corpus60s <- preprocessCorpus(filenames60s[1:10])
preprocessCorpus <- function(text_corpus){
text_corpus <- tm_map(text_corpus, stripWhitespace)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, removeWords, c(stopwords('english'),
ir_stopwords))
# text_corpus <- tm_map(text_corpus, stemDocument) #Stemming not necessary b/c the corpus has been lemmatized
text_corpus <- tm_map(text_corpus, removeNumbers)
text_corpus <- tm_map(text_corpus, removePunctuation)
return(text_corpus)
}
corpus60s <- preprocessCorpus(filenames60s[1:10])
class(ir_stopwords)
preprocessCorpus <- function(text_corpus){
text_corpus <- tm_map(text_corpus, stripWhitespace)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, removeWords, as.character(ir_stopwords))
# text_corpus <- tm_map(text_corpus, stemDocument) #Stemming not necessary b/c the corpus has been lemmatized
text_corpus <- tm_map(text_corpus, removeNumbers)
text_corpus <- tm_map(text_corpus, removePunctuation)
return(text_corpus)
}
corpus60s <- preprocessCorpus(filenames60s[1:10])
ir_stopwords <- read.csv("ir_stoplist.csv")
ir_stopwords <- as.character(ir_stopwords)
class(ir_stopwords)
ir_stopwords
words <- read.csv("ir_stoplist.csv")
words
dim(words)
class(words)
words2 <- as.character(words)
colname(words)
colnames(words)
words3 <- words$a
words3
class(words3)
words <- read.csv("ir_stoplist.csv", header=FALSE)
words
class(words)
dim(words)
colnames(words)
words2 <- words$V1
words2
class(words2)
words2 <- as.character(words$V1)
class(words2)
words2
words2 <- as.character(words)
class(words2)
words <- read.csv("ir_stoplist.csv")
class(words)
words2 <- as.character(words)
class(words2)
words2
words <- read.csv("ir_stoplist.csv", header = FALSE)
class(words)
words2 <- as.character(words)
class(words2)
words2 <- as.character(words$V1)
ir_stopwords <- read.csv("ir_stoplist.csv", header = FALSE)
ir_stopwords <- as.character(ir_stopwords$V1)
class(ir_stopwords)
ir_stopwords
preprocessCorpus <- function(text_corpus){
text_corpus <- tm_map(text_corpus, stripWhitespace)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, removeWords,ir_stopwords )
# text_corpus <- tm_map(text_corpus, stemDocument) #Stemming not necessary b/c the corpus has been lemmatized
text_corpus <- tm_map(text_corpus, removeNumbers)
text_corpus <- tm_map(text_corpus, removePunctuation)
return(text_corpus)
}
corpus60s <- preprocessCorpus(corpus60s[1:10])
corpus60s <- makeCorpus(filenames60s)
corpus60s <- preprocessCorpus(corpus60s)
dtm60s <- createDTM(corpus60s, filenames60s)
terms <- topTerms(dtm60s)
head(term)
head(terms)
head(terms, 100)
corpus70s <- makeCorpus(filenames70s)
filenames70s <- list.files("./iliff_corpus", pattern="^7")
corpus70s <- makeCorpus(filenames70s)
length(filenames70s)
corpus70s <- makeCorpus(filenames70s[1:50])
corpus70s <- makeCorpus(filenames70s[51:80])
corpus70s <- makeCorpus(filenames70s[51:60])
corpus70s <- makeCorpus(filenames70s[61:70])
corpus70s <- makeCorpus(filenames70s[71:76])
corpus70s <- makeCorpus(filenames70s[71])
corpus70s <- makeCorpus(filenames70s[72:80])
corpus70s <- makeCorpus(filenames70s[81:110])
corpus70s <- makeCorpus(filenames70s[81:139])
corpus70s <- makeCorpus(filenames70s[111:139])
filenames70s[71]
corpus80s <- makeCorpus(filenames80s)
filenames80s <- list.files("./iliff_corpus", pattern="^8")
corpus80s <- makeCorpus(filenames80s)
corpus80s <- makeCorpus(filenames80s[1:50])
corpus80s <- makeCorpus(filenames80s[51:75])
corpus80s <- makeCorpus(filenames80s[51:60])
corpus80s <- makeCorpus(filenames80s[61:69])
corpus80s <- makeCorpus(filenames80s[61:65])
corpus80s <- makeCorpus(filenames80s[66:69])
corpus80s <- makeCorpus(filenames80s[66])
corpus80s <- makeCorpus(filenames80s[67])
filenames80s[67]
corpus80s <- makeCorpus(filenames80s[68-100])
corpus80s <- makeCorpus(filenames80s[68-79])
corpus80s <- makeCorpus(filenames80s[68-74])
corpus80s <- makeCorpus(filenames80s[68])
corpus80s <- makeCorpus(filenames80s[69])
corpus80s <- makeCorpus(filenames80s[70])
corpus80s <- makeCorpus(filenames80s[71])
corpus80s <- makeCorpus(filenames80s[72])
corpus80s <- makeCorpus(filenames80s[73])
corpus80s <- makeCorpus(filenames80s[74])
corpus80s <- makeCorpus(filenames80s[75])
corpus80s <- makeCorpus(filenames80s[76:80])
corpus80s <- makeCorpus(filenames80s[81:90])
corpus80s <- makeCorpus(filenames80s[91:104])
corpus80s <- makeCorpus(filenames80s[105:120])
filenames70s[71]
# load necessary libraries
library(tm)
library(topicmodels)
library(koRpus)
library(wordcloud)
# load custom stopword list
ir_stopwords <- read.csv("ir_stoplist.csv", header = FALSE)
ir_stopwords <- as.character(ir_stopwords$V1)
#functions
abstractLemmas <- function(file){
tagged.text <- treetag(file, treetagger = "manual",
lang="en", TT.options=list(path="/Users/msaxton/treetagger/",
preset="en"))
results <- taggedText(tagged.text)
lemmas <- results[,"lemma"]
return(lemmas)
}
#the following function needs to be re-written to accept a character vector as arg
makeCorpus <- function(filenames){
file_path <- paste("./iliff_corpus/", filenames, sep="")
files <- lapply(file_path, abstractLemmas)
text_corpus <- Corpus(VectorSource(files))
return(text_corpus)
}
preprocessCorpus <- function(text_corpus){
text_corpus <- tm_map(text_corpus, stripWhitespace)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, removeWords,ir_stopwords )
# text_corpus <- tm_map(text_corpus, stemDocument) #Stemming not necessary b/c the corpus has been lemmatized
text_corpus <- tm_map(text_corpus, removeNumbers)
text_corpus <- tm_map(text_corpus, removePunctuation)
return(text_corpus)
}
createDTM <- function(corpus, filenames){
dtm <- DocumentTermMatrix(corpus)
rownames(dtm) <- filenames
return(dtm)
}
topTerms <- function(dtm){
# freq <- findFreqTerms(dtm) #not sure what this line does
sortfreq <- sort(colSums(as.matrix(dtm)), decreasing = TRUE)
return(sortfreq)
}
compareAssocTerms <- function(dtm_1, dtm_2, dtm_3, term, threshold=0.6){
print(findAssocs(dtm_1, term, threshold))
print(findAssocs(dtm_2, term, threshold))
print(findAssocs(dtm_3, term, threshold))
}
filenames60s <- list.files("./iliff_corpus", pattern="^5|^6")
filenames70s <- list.files("./iliff_corpus", pattern="^7")
filenames80s <- list.files("./iliff_corpus", pattern="^8")
corpus60s <- makeCorpus(filenames60s)
corpus60s <- preprocessCorpus(corpus60s)
dtm60s <- createDTM(corpus60s, filenames60s)
corpus70s <- makeCorpus(filenames70s)
corpus70s <- preprocessCorpus(corpus70s)
dtm70s <- createDTM(corpus70s, filenames70s)
corpus80s <- makeCorpus(filenames80s)
corpus80s <- preprocessCorpus(corpus80s)
dtm80s <- createDTM(corpus80s, filenames80s)
class(dtm80s)
m <- inspect(dtm60s)
DF <- as.data.frame(m, stringsAsFactors = FALSE)
write.table(DF)
write.csv(dtm80s, file = "dtm80s.csv")
DF <- as.data.frame(dtm80s, stringsAsFactors = FALSE)
m <- inspect(dtm80s)
DF <- as.data.frame(m, stringsAsFactors = FALSE)
write.csv(DF, file = "dtm80s.csv")
createCSV <- function(dtm, file_name){
m <- inspect(dtm)
DF <- as.data.frame(m, stringsAsFactors = FALSE)
write.csv(DF, file = file_name)
}
createCSV(dtm60s, "dtm60s.csv")
createCSV(dtm60s, "data_out/dtm60s.csv")
createCSV(dtm70s, "data_out/dtm70s.csv")
createCSV(dtm80s, "data/dtm80s.csv")
createCSV(dtm80s, "data_out/dtm80s.csv")
compareAssocTerms(dtm60s, dtm70s, dtm80s, "religion")
compareAssocTerms(dtm60s, dtm70s, dtm80s, "faith")
compareAssocTerms(dtm60s, dtm70s, dtm80s, "church")
compareAssocTerms(dtm60s, dtm70s, dtm80s, "wesley")
compareAssocTerms <- function(dtm_1, dtm_2, dtm_3, term, threshold=0.6){
print(findAssocs(dtm_1, term, threshold))
print(findAssocs(dtm_2, term, threshold))
print(findAssocs(dtm_3, term, threshold))
}
compareAssocTerms(dtm60s, dtm70s, dtm80s, "religion")
library(tm)
library(topicmodels)
library(koRpus)
library(wordcloud)
compareAssocTerms(dtm60s, dtm70s, dtm80s, "religion")
terms <- topTerms(dtm60s)
head(terms, 50)
terms70s <- topTerms(dtm70s)
head(terms70s, 50)
terms80s <- topTerms(dtm80s)
head(terms80s, 50)
writeLines(as.characer(text_corpus[[1]]))
writeLines(as.character(text_corpus[[1]]))
writeLines(as.character(corpus80s[[1]]))
dtm60s
plot(dtm60s, corThreshold = 0.80)
library(tm)
library(koRpus)
plot(dtm60s, corThreshold = 0.80)
plot(dtm70s, corThreshold = 0.80)
plot(dtm70s, corThreshold = 0.80)
plot(dtm60s, terms = names(findAssocs(dtm60s, term="religion", 0.7)[["religion"]]), corThreshold = 0.7)
findAssocs(dtm60s, term="religion", corThreshold = 0.7)
findAssocs(dtm60s, term="religion", 0.7)
findAssocs(dtm60s, term="religion", 0.65)
plot(dtm60s, terms = names(findAssocs(dtm60s, term="religion", 0.65)[["religion"]]), corThreshold = 0.65)
plot(dtm60s, terms = names(findAssocs(dtm60s, term="religion", 0.65)[["religion"]]), corThreshold = 0.5)
